{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479732f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import random\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "min=-0.5\n",
    "max=0.5\n",
    "seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a938c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mat(text=\"\",mat=[[]]):\n",
    "    print(text,end=\"\")\n",
    "    for x in mat:\n",
    "        print(\"\\t\",x)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcbe140",
   "metadata": {},
   "source": [
    "# Problem 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94c06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 0, Initialize the Weights at random \n",
    "def initialize_Weights (x_range,y_range): \n",
    "    # Return: dimensions[(x_range) x (y_range)]\n",
    "    \n",
    "    mat=[]\n",
    "    for x in range(x_range):\n",
    "        vec=[]\n",
    "        if(x==(x_range-1)):#Last Row\n",
    "            ran=randomNumber()\n",
    "            for y in range(y_range):\n",
    "                vec.append(ran)\n",
    "        else:#Rest of rowa\n",
    "            for y in range(y_range):\n",
    "                vec.append(randomNumber())\n",
    "        mat.append(vec)\n",
    "    return mat\n",
    "\n",
    "\n",
    "\n",
    "#Create nonzero random number between Max and Min\n",
    "def randomNumber():\n",
    "    value = min + (random() * (max - min))\n",
    "    if(value==0):\n",
    "        value=randomNumber()\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe22bb",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144d05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1, append to vector a number 1\n",
    "def append_1(v):\n",
    "    #v: dimensions: _x1\n",
    "    \n",
    "    v_app=[[0 for x in range(len(v[0]))] for y in range(len(v))]#Create the response matrix\n",
    "    \n",
    "    for xx, row in enumerate(v):\n",
    "        for yy, item in enumerate(row):\n",
    "            v_app[xx][yy]=item\n",
    "    \n",
    "    v_app.append([1])\n",
    "    return v_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83db005",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de66ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2, multiply f_inut and w_input\n",
    "def multiply_weights (f_input,w_input):\n",
    "    # ℎ𝑟𝑎𝑤 = 𝑎𝑝𝑝𝑒𝑛𝑑(𝑓)𝑇 * 𝑊𝑖𝑛𝑝𝑢𝑡\n",
    "    # f_input: dimensions[(a-1) x 1]\n",
    "    # w_input: dimensions[(a) x (b)]\n",
    "    # 𝑎𝑝𝑝𝑒𝑛𝑑(𝑓): dimensions[(a) x 1]\n",
    "    # 𝑎𝑝𝑝𝑒𝑛𝑑(𝑓)𝑇:dimensions[1 x (a)]\n",
    "    \n",
    "    # ℎ𝑟𝑎𝑤 = 𝑎𝑝𝑝𝑒𝑛𝑑(𝑓)𝑇 * 𝑊𝑖𝑛𝑝𝑢𝑡\n",
    "    # ℎ𝑟𝑎𝑤: dimensions[1 x (a) * (a) x (b)]\n",
    "    # ℎ𝑟𝑎𝑤: dimensions[1 x (b)]\n",
    "    \n",
    "    app_f_input=append_1(f_input)# Append 1\n",
    "    trans_app_f_input=transpose_mat(app_f_input)# Transpose\n",
    "    result = muliply_mat(trans_app_f_input,w_input)# Multiply\n",
    "    return result\n",
    "\n",
    "#transpose a matrix\n",
    "def transpose_mat(vec):\n",
    "    # t_vec = (vec)T\n",
    "    # vec: dimensions[(x) x (y)]\n",
    "    # (vec)T: dimensions[(y) x (x)]\n",
    "    \n",
    "    # t_vec = (vec)T\n",
    "    # t_vec: dimensions[(y) x (x)]\n",
    "    \n",
    "    t_vec=[]\n",
    "    for y in range(len(vec[0])):\n",
    "        row=[]\n",
    "        for x in range(len(vec)):\n",
    "            row.append(vec[x][y])\n",
    "        t_vec.append(row)\n",
    "    return t_vec\n",
    "\n",
    "#multiply matrix\n",
    "def muliply_mat(m1,m2):\n",
    "    # result = m1 * m2\n",
    "    # m1: dimensions[(a) x (b)]\n",
    "    # m2: dimensions[(b) x (c)]\n",
    "    # m1 * m2: dimensions[(a) x (c)]\n",
    "    \n",
    "    # result = m1 * m2\n",
    "    # result: dimensions[(a) x (c)]\n",
    "    \n",
    "    #Create a Matrix of 0 with the dimension of the Rowa of \"m1\" and columns of \"m2\"\n",
    "    result=[]\n",
    "    for x in range(len(m1)):\n",
    "        row=[]\n",
    "        for y in range(len(m2[0])):\n",
    "            row.append(0)\n",
    "        result.append(row)\n",
    "    #Multiply\n",
    "    for i in range(len(m1)):\n",
    "        for j in range(len(m2[0])):\n",
    "            for k in range(len(m2)):\n",
    "                multiply=m1[i][k] * m2[k][j]\n",
    "                result[i][j] += multiply\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0d187",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd964d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 3, apply sigmoid function\n",
    "def apply_sigmoid(h_raw):\n",
    "    # ℎ𝑎𝑐𝑡𝑖𝑣𝑎𝑡𝑒𝑑 = 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(ℎ𝑟𝑎𝑤)\n",
    "    # ℎ𝑟𝑎𝑤: dimensions[(a) x (b)]\n",
    "    # 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(ℎ𝑟𝑎𝑤): dimensions[(a) x (b)]\n",
    "    \n",
    "    # ℎ𝑎𝑐𝑡𝑖𝑣𝑎𝑡𝑒𝑑 = 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(ℎ𝑟𝑎𝑤)\n",
    "    # ℎ𝑎𝑐𝑡𝑖𝑣𝑎𝑡𝑒𝑑: dimensions[(a) x (b)]\n",
    "    \n",
    "    h_activated=[[0 for x in range(len(h_raw[0]))] for y in range(len(h_raw))]#Create the response matrix\n",
    "    for x, row in enumerate(h_raw):\n",
    "        for y, item in enumerate(row):\n",
    "            h_activated[x][y]=sigmoid(item)\n",
    "    return h_activated\n",
    "            \n",
    "def sigmoid(item):\n",
    "    return (1/(1+(math.exp( 0-item ))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909818a",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120a3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 4, calculate the Error\n",
    "def calculate_E(o_activated,t):\n",
    "    #E = 0.5 * (o_activated-t)T * (o_activated-t)\n",
    "    \n",
    "    diff=subtraction(o_activated,t)\n",
    "    t_diff=transpose_mat(diff)\n",
    "    \n",
    "    e=muliply_mat(t_diff,diff)\n",
    "    return 0.5*e[0][0]\n",
    "    \n",
    "def subtraction(elem1,elem2):\n",
    "    # result = elem1 - elem2\n",
    "    # elem1: dimensions[(a) x (b)]\n",
    "    # elem2: dimensions[(a) x (b)]\n",
    "    # elem1 - elem2: dimensions[(a) x (b)]\n",
    "    \n",
    "    # result = elem1 - elem2\n",
    "    # result: dimensions[(a) x (b)]\n",
    "    res=[[0 for x in range(len(elem1[0]))] for y in range(len(elem1))] #Create the response matrix\n",
    "    for x, row in enumerate(elem1):\n",
    "        for y, item in enumerate(row):\n",
    "            res[x][y]=item-elem2[x][y]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad049e31",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9bc55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 5, calculate the 𝑔(𝐸, 𝑊𝑗𝑘)\n",
    "def g_E_Wjk_fun(o_activated,t,h_activated):\n",
    "    # 𝑔(𝐸,𝑊𝑗𝑘) = (𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑇ℎ𝑖𝑑𝑗\n",
    "    # 𝑇𝑜𝑢𝑡𝑘 = o_activated\n",
    "    # 𝑡𝑎𝑟𝑔𝑘 = t\n",
    "    # 𝑇ℎ𝑖𝑑𝑗 = h_activated\n",
    "    \n",
    "    # 𝑔(𝐸,𝑊𝑗𝑘) = {[ (o_activated-t)**o_activated**(1-o_activated) ] * h_activated T} T     (**: Indicates multiply elem by elem)\n",
    "    # o_activated: dimensions[(a) x 1]    [3 x 1]\n",
    "    # t: dimensions[(a) x 1]              [3 x 1]\n",
    "    # h_activated: dimensions[(b) x 1]    [7 x 1]\n",
    "    \n",
    "    # (o_activated-t): dimensions[(a) x 1] [3 x 1]\n",
    "    o_activated_minus_t = subtraction(o_activated,t)\n",
    "    #print_mat(\"o_activated_t:\",o_activated_minus_t)\n",
    "    \n",
    "    # (1-o_activated): dimensions[(a) x 1] [3 x 1]\n",
    "    one_minus_o_activated = one_minus_mat(o_activated)\n",
    "    #print_mat(\"one_minus_o_activated:\",one_minus_o_activated)\n",
    "    \n",
    "    # (o_activated-t)**o_activated: dimensions[(a) x 1] [3 x 1]\n",
    "    o_activated_minus_t_xx_o_activated=muliply_mat_elem_by_elem(o_activated_minus_t,o_activated)\n",
    "    #print_mat(\"o_activated_minus_t_xx_o_activated:\",o_activated_minus_t_xx_o_activated)\n",
    "    \n",
    "    # (o_activated-t)**o_activated**(1-o_activated): dimensions[(a) x 1] [3 x 1]\n",
    "    o_act_m_t_xx_o_act_xx_1_m_o_act=muliply_mat_elem_by_elem(o_activated_minus_t_xx_o_activated,one_minus_o_activated)\n",
    "    #print_mat(\"o_act_m_t_xx_o_act_xx_1_m_o_act:\",o_act_m_t_xx_o_act_xx_1_m_o_act)\n",
    "    \n",
    "    # h_activated T: dimensions[1 x (b)]    [1 x 7]\n",
    "    trans_h_activated=transpose_mat(h_activated)\n",
    "    #print_mat(\"trans_h_activated:\",trans_h_activated)\n",
    "    \n",
    "    # [(o_activated-t)**o_activated**(1-o_activated)]*h_activated T: dimensions[(a) x (b)]    [3 x 7]\n",
    "    res=muliply_mat(o_act_m_t_xx_o_act_xx_1_m_o_act,trans_h_activated)\n",
    "    #print_mat(\"𝑔(𝐸,𝑊𝑗𝑘):\",res)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑊𝑗𝑘) = (𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑇ℎ𝑖𝑑𝑗\n",
    "    # 𝑔(𝐸,𝑊𝑗𝑘) = {[ (o_activated-t)**o_activated**(1-o_activated) ] * h_activated T} T \n",
    "    # 𝑔(𝐸,𝑊𝑗𝑘): dimensions[(b) x (a)] [7 x 3]\n",
    "    return transpose_mat(res)#We return the transpose for better use later in updating the weights\n",
    "    \n",
    "def one_minus_mat(mat):\n",
    "    # result = 1 - mat\n",
    "        # res ij = 1 - mat ij (0<i<a,0<j<b)\n",
    "    # mat: dimensions[(a) x (b)]\n",
    "    # 1 - mat: dimensions[(a) x (b)]\n",
    "    \n",
    "    # result = 1 - mat\n",
    "    # result: dimensions[(a) x (b)]\n",
    "    res=[[0 for x in range(len(mat[0]))] for y in range(len(mat))] #Create the response matrix\n",
    "    for x, row in enumerate(mat):\n",
    "        for y, item in enumerate(row):\n",
    "            res[x][y]=1-item\n",
    "    return res\n",
    "\n",
    "def muliply_mat_elem_by_elem(mat1,mat2):\n",
    "    # result = mat1 * mat2\n",
    "        # res ij = mat1 ij * mat2 ij (0<i<a,0<j<b)\n",
    "    # mat1: dimensions[(a) x (b)]\n",
    "    # mat2: dimensions[(a) x (b)]\n",
    "    # mat1 * mat2: dimensions[(a) x (b)]\n",
    "    \n",
    "    # result = mat1 * mat2\n",
    "    # result: dimensions[(a) x (b)]\n",
    "    \n",
    "    res=[[0 for x in range(len(mat1[0]))] for y in range(len(mat1))] #Create the response matrix\n",
    "    for x, row in enumerate(mat1):\n",
    "        for y, item in enumerate(row):\n",
    "            res[x][y]=mat1[x][y]*mat2[x][y]\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce085e",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62daaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 6, calculate the 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂)\n",
    "def g_E_biasO_fun(o_activated,t):\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂) = Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)]\n",
    "    # 𝑇𝑜𝑢𝑡𝑘 = o_activated\n",
    "    # 𝑡𝑎𝑟𝑔𝑘 = t\n",
    "    \n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂) = Σ𝑘[(o_activated-t)*o_activated*(1-o_activated)]\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂) = Σ𝑘[(o_activated-t)**o_activated**(1-o_activated)]      (**: Indicates multiply elem by elem)\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂) = ones * [(o_activated-t)**o_activated**(1-o_activated)] (Multiply by a row of ones in order to add)\n",
    "    # o_activated: dimensions[(a) x 1]    [3 x 1]\n",
    "    # t: dimensions[(a) x 1]              [3 x 1]\n",
    "    # ones: dimensions[1 x (a)]           [1 x 3]   (Form by 1's) (1 ... 1)\n",
    "    \n",
    "    # [(o_activated-t)**o_activated**(1-o_activated)]: dimensions[(a) x 1] [3 x 1] (Same as Problem 5)\n",
    "    o_activated_minus_t = subtraction(o_activated,t)\n",
    "    one_minus_o_activated = one_minus_mat(o_activated)\n",
    "    o_activated_minus_t_xx_o_activated=muliply_mat_elem_by_elem(o_activated_minus_t,o_activated)\n",
    "    o_act_m_t_xx_o_act_xx_1_m_o_act=muliply_mat_elem_by_elem(o_activated_minus_t_xx_o_activated,one_minus_o_activated)\n",
    "    #print_mat(\"o_act_m_t_xx_o_act_xx_1_m_o_act:\",o_act_m_t_xx_o_act_xx_1_m_o_act)\n",
    "    \n",
    "    # (1 ... 1): dimensions[1 x (a)] [1 x 3]\n",
    "    ones=[[1 for x in range(len(o_act_m_t_xx_o_act_xx_1_m_o_act))]]\n",
    "    #print_mat(\"ones:\",ones)\n",
    "    \n",
    "    # ones * [(o_activated-t)**o_activated**(1-o_activated)] : dimensions[1 x 1]\n",
    "    res=muliply_mat(ones,o_act_m_t_xx_o_act_xx_1_m_o_act)\n",
    "    #print_mat(\"𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂):\",res)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂) = Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)]\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂) = ones * [(o_activated-t)**o_activated**(1-o_activated)] \n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂): dimensions[1 x 1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689d952",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e666b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 7, calculate the 𝑔(𝐸,𝑤𝑖𝑗)\n",
    "def g_E_wij_fun(o_activated,t,w_hidden,h_activated,f_input):\n",
    "    # 𝑔(𝐸,𝑤𝑖𝑗) = Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑊𝑗𝑘]∙𝑇ℎ𝑖𝑑𝑗∙(1−𝑇ℎ𝑖𝑑𝑗)∙𝑖𝑛𝑝𝑖\n",
    "    # 𝑇𝑜𝑢𝑡𝑘 = o_activated\n",
    "    # 𝑡𝑎𝑟𝑔𝑘 = t\n",
    "    # 𝑊𝑗𝑘 = w_hidden\n",
    "    # 𝑇ℎ𝑖𝑑𝑗 = h_activated\n",
    "    # 𝑖𝑛𝑝𝑖 = f_input\n",
    "    # Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑊𝑗𝑘] = 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑤𝑖𝑗) = 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)*h_activated*(1-h_activated)*f_input\n",
    "    # 𝑔(𝐸,𝑤𝑖𝑗) = {[𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)**h_activated**(1-h_activated)]*f_input T} T\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗): dimensions[(a) x 1]    [7 x 1]\n",
    "    # h_activated: dimensions[(a) x 1]    [7 x 1]\n",
    "    # f_input: dimensions[(b) x 1]    [7 x 1]\n",
    "    \n",
    "    # (1-h_activated): dimensions[(a) x 1] [7 x 1]\n",
    "    one_minus_h_activated = one_minus_mat(h_activated)\n",
    "    #print_mat(\"one_minus_h_activated:\",one_minus_h_activated)\n",
    "\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗): dimensions[(a) x 1]    [7 x 1]\n",
    "    g_E_Thidj = g_E_Thidj_fun(o_activated,t,w_hidden)\n",
    "    #print_mat(\"𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗):\",g_E_Thidj)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)**h_activated: dimensions[(a) x 1] [7 x 1]\n",
    "    g_E_Thidj_xx_h_activated = muliply_mat_elem_by_elem(g_E_Thidj,h_activated)\n",
    "    #print_mat(\"g_E_Thidj_xx_h_activated:\",g_E_Thidj_xx_h_activated)\n",
    "    \n",
    "    # [𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)**h_activated**(1-h_activated)]: dimensions[(a) x 1] [7 x 1]\n",
    "    g_E_Thidj_xx_h_act_xx_one_minus_h_act = muliply_mat_elem_by_elem(g_E_Thidj_xx_h_activated,one_minus_h_activated)\n",
    "    #print_mat(\"g_E_Thidj_xx_h_act_xx_one_minus_h_act:\",g_E_Thidj_xx_h_act_xx_one_minus_h_act)\n",
    "        \n",
    "    # f_input T: dimensions[1 x (b)] [1 x 7]\n",
    "    trans_f_input=transpose_mat(f_input)\n",
    "    #print_mat(\"trans_f_input:\",trans_f_input)\n",
    "    \n",
    "    # [𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)**h_activated**(1-h_activated)]*f_input T: dimensions[(a) x (b)] [7 x 7]\n",
    "    res=muliply_mat(g_E_Thidj_xx_h_act_xx_one_minus_h_act,trans_f_input)\n",
    "    #print_mat(\"𝑔(𝐸,𝑤𝑖𝑗):\",res)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑤𝑖𝑗) = Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑊𝑗𝑘]∙𝑇ℎ𝑖𝑑𝑗∙(1−𝑇ℎ𝑖𝑑𝑗)∙𝑖𝑛𝑝𝑖\n",
    "    # 𝑔(𝐸,𝑤𝑖𝑗) = {[𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)**h_activated**(1-h_activated)]*f_input T} T\n",
    "    # 𝑔(𝐸,𝑤𝑖𝑗): dimensions[(b) x (a)] [7 x 7]\n",
    "    return transpose_mat(res)#We return the transpose for better use later in updating the weights\n",
    "    \n",
    "    \n",
    "    \n",
    "#Calculate 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)\n",
    "def g_E_Thidj_fun(o_activated,t,w_hidden):\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗) = Σ𝑘(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∗𝑇𝑜𝑢𝑡𝑘∗(1−𝑇𝑜𝑢𝑡𝑘)∗𝑊𝑗𝑘\n",
    "    # 𝑇𝑜𝑢𝑡𝑘 = o_activated\n",
    "    # 𝑡𝑎𝑟𝑔𝑘 = t\n",
    "    # 𝑊𝑗𝑘 = w_hidden\n",
    "\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗) = Σ𝑘[(o_activated-t)*o_activated*(1-o_activated)*w_hidden]\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗) = Σ𝑘[(o_activated-t)**o_activated**(1-o_activated)*w_hidden] (**: Indicates multiply elem by elem)\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗) = w_hidden * [(o_activated-t)**o_activated**(1-o_activated)]\n",
    "    # o_activated: dimensions[(a) x 1]    [3 x 1]\n",
    "    # t: dimensions[(a) x 1]              [3 x 1]\n",
    "    # w_hidden [(b) x (a)]                [8 x 3] (We need to ignore the last row, belongs to the bias)\n",
    "    \n",
    "    # [(o_activated-t)**o_activated**(1-o_activated)]: dimensions[(a) x 1] [3 x 1] (Same as Problem 5 & 6)\n",
    "    o_activated_minus_t = subtraction(o_activated,t)\n",
    "    one_minus_o_activated = one_minus_mat(o_activated)\n",
    "    o_activated_minus_t_xx_o_activated = muliply_mat_elem_by_elem(o_activated_minus_t,o_activated)\n",
    "    o_act_m_t_xx_o_act_xx_1_m_o_act = muliply_mat_elem_by_elem(o_activated_minus_t_xx_o_activated,one_minus_o_activated)\n",
    "    #print_mat(\"o_act_m_t_xx_o_act_xx_1_m_o_act:\",o_act_m_t_xx_o_act_xx_1_m_o_act)\n",
    "    \n",
    "    # w_hidden * [(o_activated-t)**o_activated**(1-o_activated)]: dimensions[(b-1) x 1] [7 x 1]\n",
    "    w_hid_x_o_act_m_t_xx_o_act_xx_1_m_o_act = muliply_mat(w_hidden[:-1],o_act_m_t_xx_o_act_xx_1_m_o_act)\n",
    "    #print_mat(\"w_hid_x_o_act_m_t_xx_o_act_xx_1_m_o_act:\",w_hid_x_o_act_m_t_xx_o_act_xx_1_m_o_act)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗) = Σ𝑘(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∗𝑇𝑜𝑢𝑡𝑘∗(1−𝑇𝑜𝑢𝑡𝑘)∗𝑊𝑗𝑘\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗) = w_hidden * [(o_activated-t)**o_activated**(1-o_activated)]\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗): dimensions [7 x 1]\n",
    "    return w_hid_x_o_act_m_t_xx_o_act_xx_1_m_o_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d0e0a",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9f59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 8, calculate the 𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻)\n",
    "def g_E_biasH_fun(o_activated,t,w_hidden,h_activated):\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻) = Σ𝑗[Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑊𝑗𝑘]∙Thid𝑗∙(1−Thid𝑗)]\n",
    "    # 𝑇𝑜𝑢𝑡𝑘 = o_activated\n",
    "    # 𝑡𝑎𝑟𝑔𝑘 = t\n",
    "    # 𝑊𝑗𝑘 = w_hidden\n",
    "    # 𝑇ℎ𝑖𝑑𝑗 = h_activated\n",
    "    # Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑊𝑗𝑘] = 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻) = Σ𝑗[𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)*h_activated*(1−h_activated)]\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻) = ones*[𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)** h_activated**(1−h_activated)]\n",
    "    # 𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗): dimensions[(a) x 1]    [7 x 1]\n",
    "    # h_activated: dimensions[(a) x 1]    [7 x 1]\n",
    "    # ones: dimensions[1 x (a)]           [1 x 7]   (Form by 1's) (1 ... 1)\n",
    "    \n",
    "    # [𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)**h_activated**(1-h_activated)]: dimensions[(a) x 1] [7 x 1]\n",
    "    g_E_Thidj                             = g_E_Thidj_fun(o_activated,t,w_hidden)\n",
    "    one_minus_h_activated                 = one_minus_mat(h_activated)\n",
    "    g_E_Thidj_xx_h_activated              = muliply_mat_elem_by_elem(g_E_Thidj,h_activated)\n",
    "    g_E_Thidj_xx_h_act_xx_one_minus_h_act = muliply_mat_elem_by_elem(g_E_Thidj_xx_h_activated,one_minus_h_activated)\n",
    "    #print_mat(\"g_E_Thidj_xx_h_act_xx_one_minus_h_act:\",g_E_Thidj_xx_h_act_xx_one_minus_h_act)\n",
    "    \n",
    "    # (1 ... 1): dimensions[1 x (a)] [1 x 7]\n",
    "    ones=[[1 for x in range(len(g_E_Thidj_xx_h_act_xx_one_minus_h_act))]]\n",
    "    #print_mat(\"ones:\",ones)\n",
    "    \n",
    "    # ones * [𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)**h_activated**(1-h_activated)] : dimensions[1 x 1]\n",
    "    res=muliply_mat(ones,g_E_Thidj_xx_h_act_xx_one_minus_h_act)\n",
    "    #print_mat(\"𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻):\",res)\n",
    "    \n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻) = Σ𝑗[Σ𝑘[(𝑇𝑜𝑢𝑡𝑘−𝑡𝑎𝑟𝑔𝑘)∙𝑇𝑜𝑢𝑡𝑘∙(1−𝑇𝑜𝑢𝑡𝑘)∙𝑊𝑗𝑘]∙Thid𝑗∙(1−Thid𝑗)]\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻) = ones*[𝑔(𝐸,𝑇ℎ𝑖𝑑𝑗)** h_activated**(1−h_activated)]\n",
    "    # 𝑔(𝐸,𝑏𝑖𝑎𝑠𝐻): dimensions[1 x 1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e936d46",
   "metadata": {},
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e59f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 9, update the weights for the Input-to-hidden layer\n",
    "def update_weights_input_hidden(alpha,w_input,o_activated,t,w_hidden,h_activated,f_input):\n",
    "    #Get gradient\n",
    "    g_E_wij   = g_E_wij_fun(o_activated,t,w_hidden,h_activated,f_input)\n",
    "    g_E_biasH = g_E_biasH_fun(o_activated,t,w_hidden,h_activated)\n",
    "    \n",
    "    for x in range(len(w_input)):\n",
    "        for y in range(len(w_input[0])):\n",
    "            if(x==(len(w_input)-1)):#Bias\n",
    "                w_input[x][y]=w_input[x][y] - (alpha * g_E_biasH[0][0])\n",
    "            else:#Normal Weights\n",
    "                w_input[x][y]=w_input[x][y] - (alpha * g_E_wij[x][y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4661dc5d",
   "metadata": {},
   "source": [
    "# Problem 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c171b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 10, update the weights for the Hidden-to-output layer\n",
    "def update_weights_hidden_output(alpha,w_hidden,o_activated,t,h_activated):\n",
    "    #Get gradient\n",
    "    g_E_Wjk   = g_E_Wjk_fun(o_activated,t,h_activated)\n",
    "    g_E_biasO = g_E_biasO_fun(o_activated,t)\n",
    "    \n",
    "    for x in range(len(w_hidden)):\n",
    "        for y in range(len(w_hidden[0])):\n",
    "            if(x==(len(w_hidden)-1)):#Bias\n",
    "                w_hidden[x][y]=w_hidden[x][y] - (alpha * g_E_biasO[0][0])\n",
    "            else:#Normal Weights\n",
    "                w_hidden[x][y]=w_hidden[x][y] - (alpha * g_E_Wjk[x][y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8eafbc",
   "metadata": {},
   "source": [
    "# Problem 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba167ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 11, Putting Everything Together (Almost)\n",
    "def putting_everything_together(f_input,t,alpha=0.2,w_input=None,w_hidden=None):\n",
    "    #If no Weights are given, we consider it to be the first iteration, so new weights are created\n",
    "    if w_input==None:\n",
    "        print(\"Generating the input-hidden weights...\")\n",
    "        print(\"...\")\n",
    "        w_input=initialize_Weights(8,7)\n",
    "        print_mat(\"Input Weights:\\n\",w_input)\n",
    "        print(\"The weights have been generated\")\n",
    "    if w_hidden==None:\n",
    "        print(\"Generating the hidden-output weights...\")\n",
    "        print(\"...\")\n",
    "        w_hidden=initialize_Weights(8,3)\n",
    "        print_mat(\"Hidden Weights:\\n\",w_hidden)\n",
    "        print(\"The weights have been generated\")\n",
    "    print()\n",
    "    ###############################\n",
    "    ##### Forward Propagation #####\n",
    "    ###############################\n",
    "    \n",
    "    print(\"Doing Forward Propagation...\")\n",
    "    print(\"...\")\n",
    "    #h_raw: Input vector multiply by input Weights\n",
    "    h_raw=multiply_weights(f_input,w_input)\n",
    "    #print_mat(\"h raw:\",transpose_mat(h_raw))\n",
    "\n",
    "    #h_activated: activated values for hidden layer\n",
    "    h_activated=apply_sigmoid(transpose_mat(h_raw))\n",
    "    #print_mat(\"h_activated:\",h_activated)\n",
    "    \n",
    "    #o_raw: hidden vector multiply by hidden Weights\n",
    "    o_raw=multiply_weights(h_activated,w_hidden)\n",
    "    #print_mat(\"o raw:\",transpose_mat(o_raw))\n",
    "\n",
    "    #o_activated: activated values for output layer\n",
    "    o_activated=apply_sigmoid(transpose_mat(o_raw))\n",
    "    print_mat(\"Predicted Output:\",o_activated)\n",
    "    \n",
    "    print_mat(\"True Output:\",t)\n",
    "    print(\"Finished Forward Propagation\")\n",
    "    print()\n",
    "    #################\n",
    "    ##### Error #####\n",
    "    #################\n",
    "    e=calculate_E(o_activated,t)\n",
    "    print(\"Error: \",e)\n",
    "    print()\n",
    "    ################################\n",
    "    ##### Backward Propagation #####\n",
    "    ################################\n",
    "    \n",
    "    print(\"Doing Backward Propagation...\")\n",
    "    print(\"...\")\n",
    "    update_weights_input_hidden(alpha,w_input,o_activated,t,w_hidden,h_activated,f_input)\n",
    "    #print_mat(\"Weights Input Updated:\\n\",w_input)\n",
    "\n",
    "    update_weights_hidden_output(alpha,w_hidden,o_activated,t,h_activated)\n",
    "    #print_mat(\"Weights Hidden Updated:\\n\",w_hidden)\n",
    "    print(\"Finished Backward Propagation\")\n",
    "    print()\n",
    "    \n",
    "    print(\"New Weights:\")\n",
    "    print()\n",
    "    print_mat(\"Input Weights:\\n\",w_input)\n",
    "    print()\n",
    "    print_mat(\"Hidden Weights:\\n\",w_hidden)\n",
    "    print()\n",
    "    return (w_input,w_hidden)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e16b5617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the input-hidden weights...\n",
      "...\n",
      "Input Weights:\n",
      "\t [-0.3656357558875988, 0.3474337369372327, 0.26377461897661403, -0.2449309742605783, -0.004564912908059049, -0.050508935211261874, 0.15159297272276295]\n",
      "\t [0.2887233511355132, -0.4061404132257651, -0.4716525234779937, 0.3357651039198697, -0.06723293209494663, 0.262280082457942, -0.4978939466488893]\n",
      "\t [-0.05461280594519857, 0.22154003234078257, -0.27123777872954735, 0.4452706955539223, 0.4014274576114836, -0.46941001696644646, -0.4745541390065392]\n",
      "\t [0.04141247279349658, 0.43914916277851057, -0.11879576231178757, -0.2834006028693866, -0.07788342441728269, -0.47095921242513206, -0.27830833372696495]\n",
      "\t [-0.06211240634942794, -0.004187758618149351, -0.26691554974242737, -0.2691334584590157, -0.2812189626623114, -0.040396534262266415, -0.21021838540951443]\n",
      "\t [-0.4785102947340911, 0.33757797566257286, 0.05645432265243344, 0.14229436293244557, -0.3140937341052823, 0.4925434121760651, 0.3599465287952899]\n",
      "\t [-0.3791100401941936, -0.1673048146398709, 0.22148440758326837, 0.21119176969527964, 0.43644058679945963, -0.07789300003858479, 0.330035693274327]\n",
      "\t [0.17030556641407102, 0.17030556641407102, 0.17030556641407102, 0.17030556641407102, 0.17030556641407102, 0.17030556641407102, 0.17030556641407102]\n",
      "\n",
      "The weights have been generated\n",
      "Generating the hidden-output weights...\n",
      "...\n",
      "Hidden Weights:\n",
      "\t [-0.1966314890670824, 0.08758060614355945, 0.3824790008318577]\n",
      "\t [0.34619741842831275, 0.005283820579600418, 0.08900225798255168]\n",
      "\t [-0.4654741698486584, -0.25726002645693236, 0.29740424755430284]\n",
      "\t [-0.08568600069922572, -0.3269925984209491, 0.04879876138815298]\n",
      "\t [0.20304076206563149, 0.17448583050232724, -0.12529697949835972]\n",
      "\t [-0.06103836995543688, 0.008426488249981823, 0.2784426150001458]\n",
      "\t [0.020938417613145188, -0.10674490503577394, -0.010306479537741775]\n",
      "\t [-0.47042503603309294, -0.47042503603309294, -0.47042503603309294]\n",
      "\n",
      "The weights have been generated\n",
      "\n",
      "Doing Forward Propagation...\n",
      "...\n",
      "Predicted Output:\t [0.45093482253133077]\n",
      "\t [0.32254568299751624]\n",
      "\t [0.43639408925425904]\n",
      "\n",
      "True Output:\t [1]\n",
      "\t [0]\n",
      "\t [0]\n",
      "\n",
      "Finished Forward Propagation\n",
      "\n",
      "Error:  0.29797404393254484\n",
      "\n",
      "Doing Backward Propagation...\n",
      "...\n",
      "Finished Backward Propagation\n",
      "\n",
      "New Weights:\n",
      "\n",
      "Input Weights:\n",
      "\t [-0.36569866951802177, 0.34778161842721145, 0.26109694288399055, -0.244779447840118, -0.0032850010612779142, -0.05235705678757851, 0.1521606083864]\n",
      "\t [0.28859752387466725, -0.40544465024580756, -0.4770078756632406, 0.3360681567607903, -0.06467310840138436, 0.2585838393053087, -0.4967586753216152]\n",
      "\t [-0.054801546836467485, 0.22258367681071886, -0.27927080700741774, 0.4457252748153033, 0.40526719315182697, -0.4749543816953964, -0.47285123201562806]\n",
      "\t [0.0411608182718047, 0.44054068873842567, -0.1295064666822814, -0.2827944971875453, -0.07276377703015816, -0.4783516987303986, -0.27603779107241677]\n",
      "\t [-0.06242697450154279, -0.0024483511682555125, -0.28030393020554467, -0.26837582635671403, -0.2748194034284057, -0.0496371421438496, -0.20738020709132923]\n",
      "\t [-0.47888777651662895, 0.33966526460244545, 0.040388266096692674, 0.14320352145520757, -0.3064142630245955, 0.48145468271816527, 0.3633523427771121]\n",
      "\t [-0.3795504356071544, -0.16486964421001954, 0.20274067493490414, 0.21225245463850195, 0.4453999697269276, -0.09082985107280125, 0.3340091429197863]\n",
      "\t [0.1680638105355652, 0.1680638105355652, 0.1680638105355652, 0.1680638105355652, 0.1680638105355652, 0.1680638105355652, 0.1680638105355652]\n",
      "\n",
      "\n",
      "Hidden Weights:\n",
      "\t [-0.19651534666997267, 0.08752039294592609, 0.38238730228200646]\n",
      "\t [0.37204691589275296, -0.008117667062151765, 0.06859316112506389]\n",
      "\t [-0.4593889396883474, -0.26041487064308383, 0.2925997420929204]\n",
      "\t [-0.06240193234312516, -0.33906405763416025, 0.030415161978928865]\n",
      "\t [0.22113829236257773, 0.16510329496350673, -0.13958562279673709]\n",
      "\t [-0.05038531371277103, 0.0029034872021133223, 0.2700316485206649]\n",
      "\t [0.03594196240854098, -0.11452338585284101, -0.022152311332194457]\n",
      "\t [-0.4787986288604477, -0.4787986288604477, -0.4787986288604477]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test for Putting Everything Together (Almost)\n",
    "\n",
    "f_input=[[1],\n",
    "         [2],\n",
    "         [3],\n",
    "         [4],\n",
    "         [5],\n",
    "         [6],\n",
    "         [7]]\n",
    "vec2=[[1],\n",
    "      [0],\n",
    "      [0]]\n",
    "\n",
    "w_input,w_hidden=putting_everything_together(f_input,vec2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4e3a1",
   "metadata": {},
   "source": [
    "# TESTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for Forward Propagation\n",
    "\n",
    "#Create the Weights for input layer\n",
    "w_input=initialize_Weights(8,7)\n",
    "print_mat(\"Weights Input:\",w_input)\n",
    "\n",
    "#Input vector\n",
    "f_input=[[1],\n",
    "         [2],\n",
    "         [3],\n",
    "         [4],\n",
    "         [5],\n",
    "         [6],\n",
    "         [7]]\n",
    "v=append_1(f_input)\n",
    "print_mat(\"Append:\",v)\n",
    "v=transpose_mat(v)\n",
    "print_mat(\"Transpose:\",v)\n",
    "\n",
    "\n",
    "#h_raw: Input vector multiply by input Weights\n",
    "h_raw=multiply_weights(f_input,w_input)\n",
    "print_mat(\"h raw:\",transpose_mat(h_raw))\n",
    "\n",
    "#h_activated: activated values for hidden layer\n",
    "h_activated=apply_sigmoid(transpose_mat(h_raw))\n",
    "print_mat(\"h_activated:\",h_activated)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#Create the Weights for hidden layer\n",
    "w_hidden=initialize_Weights(8,3)\n",
    "print_mat(\"Weights hidden:\",w_hidden)\n",
    "\n",
    "#o_raw: hidden vector multiply by hidden Weights\n",
    "o_raw=multiply_weights(h_activated,w_hidden)\n",
    "print_mat(\"o raw:\",transpose_mat(o_raw))\n",
    "\n",
    "#o_activated: activated values for output layer\n",
    "o_activated=apply_sigmoid(transpose_mat(o_raw))\n",
    "print_mat(\"o_activated:\",o_activated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for Error\n",
    "vec1=[[1],\n",
    "      [2],\n",
    "      [3]]\n",
    "vec2=[[1],\n",
    "      [0],\n",
    "      [0]]\n",
    "\n",
    "#o=subtraction(vec1,vec2)\n",
    "#print(vec1)\n",
    "#print(vec2)\n",
    "#print(o)\n",
    "\n",
    "ee=calculate_E(vec1,vec2)\n",
    "\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523deb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for Backward Propagation\n",
    "\n",
    "print_mat(\"o_activated:\",o_activated)\n",
    "print_mat(\"t:\",vec2)\n",
    "print_mat(\"h_activated:\",h_activated)\n",
    "\n",
    "g_E_Wjk=g_E_Wjk_fun(o_activated,vec2,h_activated)\n",
    "print_mat(\"𝑔(𝐸,𝑊𝑗𝑘):\",g_E_Wjk)\n",
    "\n",
    "g_E_biasH=g_E_biasO_fun(o_activated,vec2)\n",
    "print_mat(\"𝑔(𝐸,𝑏𝑖𝑎𝑠𝑂):\",g_E_biasH)\n",
    "\n",
    "#g_E_Thidj=g_E_Thidj_fun(o_activated,vec2,w_hidden)\n",
    "#print_mat(\"𝑔(𝐸,Thidj):\",g_E_Thidj)\n",
    "\n",
    "g_E_wij=g_E_wij_fun(o_activated,vec2,w_hidden,h_activated,f_input)\n",
    "print_mat(\"𝑔(𝐸,𝑤𝑖𝑗):\",g_E_wij)\n",
    "\n",
    "\n",
    "g_E_biasH=g_E_biasH_fun(o_activated,vec2,w_hidden,h_activated)\n",
    "print_mat(\"𝑔(𝐸,biasH):\",g_E_biasH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc760d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Gradient Descent\n",
    "\n",
    "update_weights_input_hidden(0.2,w_input,o_activated,vec2,w_hidden,h_activated,f_input)\n",
    "print_mat(\"Weights Input Updated:\\n\",w_input)\n",
    "\n",
    "\n",
    "update_weights_hidden_output(0.2,w_hidden,o_activated,vec2,h_activated)\n",
    "print_mat(\"Weights hidden Updated:\\n\",w_hidden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
